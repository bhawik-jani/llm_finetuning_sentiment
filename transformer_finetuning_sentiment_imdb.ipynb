{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6e4c88f-950e-4aed-a165-5ac5deb0e62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from transformer import Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfd8547-1a6e-41ce-9f2f-e301470ec332",
   "metadata": {},
   "source": [
    "## Finetuning on unsupervised IMDB text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b907112f-e094-41f2-8d2f-b5371657a103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec68d752-b941-42c2-adef-b930f0cf13a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Kwaai/IMDB_Sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b034b88c-e588-43d9-9768-dc89b4898a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a5f06ad-b6de-447a-a53c-19ab1b1d5bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'This is just a precious little diamond. The play, the script are excellent. I cant compare this movie with anything else, maybe except the movie \"Leon\" wonderfully played by Jean Reno and Natalie Portman. But... What can I say about this one? This is the best movie Anne Parillaud has ever played in (See please \"Frankie Starlight\", she\\'s speaking English there) to see what I mean. The story of young punk girl Nikita, taken into the depraved world of the secret government forces has been exceptionally over used by Americans. Never mind the \"Point of no return\" and especially the \"La femme Nikita\" TV series. They cannot compare the original believe me! Trash these videos. Buy this one, do not rent it, BUY it. BTW beware of the subtitles of the LA company which \"translate\" the US release. What a disgrace! If you cant understand French, get a dubbed version. But you\\'ll regret later :)',\n",
       " 'label': -1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['unsupervised'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fef29f7f-cd0a-4af8-baf6-10bf652c8ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for x in dataset['unsupervised']:\n",
    "    l.append(x['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6274312-08fc-40e3-a94f-ef77b4022358",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80414d81-1deb-4ed2-92c7-3ff1eb8d8fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8bc6840-ba69-4834-ae32-64e4b3e8b3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = nn.Embedding(vocab_size, d_model)\n",
    "        self.position_embedding = nn.Embedding(block_size, d_model)\n",
    "        self.transformer = Transformer(num_layers, d_model, nhead, dim_feedforward, dropout=dropout)\n",
    "        self.final = nn.Linear(d_model, vocab_size)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=(2/d_model)**0.5)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=(2/vocab_size)**0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T = x.shape\n",
    "        tok_emb = self.embedding_layer(x) # (B,T,C)\n",
    "        pos_emb = self.position_embedding(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.transformer(x, mask=mask) # (B,T,C)\n",
    "        logits = self.final(x) # (B,T,vocab_size)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2be0dacd-274f-469f-9b53-02aa92120220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "702c83fa-23d8-43af-aabb-4207ebdd0a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "accumulation_steps = 8\n",
    "block_size = 512\n",
    "num_iters = 30000\n",
    "print_interval = 100\n",
    "val_iters = 8\n",
    "lr = 5e-4\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "d_model = 256\n",
    "nhead = 8\n",
    "num_layers = 8\n",
    "dropout = 0.01\n",
    "dim_feedforward = 2048\n",
    "mask = torch.tril(torch.ones(block_size,block_size)).to(device=device)\n",
    "vocab_size = tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba945fc3-8234-4a02-8c69-9c70182dc9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "scaler = GradScaler()  # Helps prevent underflow issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfa8b1a1-2d6a-4173-9881-3ef0ea05b436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (15022801 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# Train and test splits\n",
    "data = tokenizer(text, return_tensors=\"pt\")[\"input_ids\"][0]\n",
    "n = int(0.96*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e985394-6977-4a73-a4c5-4aa812e5e4e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15022801"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d855bcf0-19c3-44b0-9a99-0f97a9c94a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iters = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95fab58d-6b35-44af-a0a2-8ee669e40d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.427857 M parameters\n"
     ]
    }
   ],
   "source": [
    "model = LanguageModel()\n",
    "checkpoint = torch.load(\"wiki103_checkpoint.pth\")\n",
    "model.load_state_dict(checkpoint[\"model_state\"])\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "270787ee-7b08-40a6-ac66-a45d5731668e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 7.8739, val loss 7.9724\n",
      "step 100: train loss 6.7880, val loss 5.8183\n",
      "step 200: train loss 5.5548, val loss 5.3416\n",
      "step 300: train loss 5.2586, val loss 5.2070\n",
      "step 400: train loss 5.1132, val loss 5.1065\n",
      "step 500: train loss 5.0190, val loss 4.9744\n",
      "step 600: train loss 4.9713, val loss 4.9203\n",
      "step 700: train loss 4.9073, val loss 4.8497\n",
      "step 800: train loss 4.8601, val loss 4.8543\n",
      "step 900: train loss 4.8508, val loss 4.8648\n",
      "step 1000: train loss 4.8065, val loss 4.8360\n",
      "step 1100: train loss 4.7738, val loss 4.7851\n",
      "step 1200: train loss 4.7746, val loss 4.7549\n",
      "step 1300: train loss 4.7224, val loss 4.8008\n",
      "step 1400: train loss 4.7378, val loss 4.7828\n",
      "step 1500: train loss 4.7170, val loss 4.7392\n",
      "step 1600: train loss 4.6827, val loss 4.7427\n",
      "step 1700: train loss 4.6818, val loss 4.7445\n",
      "step 1800: train loss 4.6542, val loss 4.6890\n",
      "step 1900: train loss 4.6450, val loss 4.7248\n",
      "step 2000: train loss 4.6229, val loss 4.6693\n",
      "step 2100: train loss 4.6114, val loss 4.7000\n",
      "step 2200: train loss 4.5962, val loss 4.6764\n",
      "step 2300: train loss 4.5725, val loss 4.6691\n",
      "step 2400: train loss 4.6020, val loss 4.6600\n",
      "step 2500: train loss 4.5642, val loss 4.6968\n",
      "step 2600: train loss 4.5577, val loss 4.6203\n",
      "step 2700: train loss 4.5519, val loss 4.6311\n",
      "step 2800: train loss 4.5224, val loss 4.6056\n",
      "step 2900: train loss 4.5180, val loss 4.6392\n",
      "step 3000: train loss 4.5070, val loss 4.6129\n",
      "step 3100: train loss 4.5126, val loss 4.6010\n",
      "step 3200: train loss 4.4998, val loss 4.5491\n",
      "step 3300: train loss 4.4883, val loss 4.6335\n",
      "step 3400: train loss 4.4745, val loss 4.5832\n",
      "step 3500: train loss 4.4628, val loss 4.5398\n",
      "step 3600: train loss 4.4717, val loss 4.5934\n",
      "step 3700: train loss 4.4437, val loss 4.5537\n",
      "step 3800: train loss 4.4244, val loss 4.5710\n",
      "step 3900: train loss 4.4328, val loss 4.5729\n",
      "step 4000: train loss 4.4323, val loss 4.5213\n",
      "step 4100: train loss 4.4179, val loss 4.4922\n",
      "step 4200: train loss 4.4351, val loss 4.5624\n",
      "step 4300: train loss 4.4247, val loss 4.5299\n",
      "step 4400: train loss 4.4094, val loss 4.5420\n",
      "step 4500: train loss 4.3872, val loss 4.5813\n",
      "step 4600: train loss 4.3850, val loss 4.5002\n",
      "step 4700: train loss 4.3816, val loss 4.5446\n",
      "step 4800: train loss 4.3671, val loss 4.5078\n",
      "step 4900: train loss 4.3815, val loss 4.5583\n",
      "step 5000: train loss 4.3644, val loss 4.5512\n",
      "step 5100: train loss 4.3677, val loss 4.5414\n",
      "step 5200: train loss 4.3550, val loss 4.4796\n",
      "step 5300: train loss 4.3546, val loss 4.5017\n",
      "step 5400: train loss 4.3509, val loss 4.5160\n",
      "step 5500: train loss 4.3422, val loss 4.5334\n",
      "step 5600: train loss 4.3277, val loss 4.4823\n",
      "step 5700: train loss 4.3284, val loss 4.4930\n",
      "step 5800: train loss 4.3213, val loss 4.5199\n",
      "step 5900: train loss 4.3135, val loss 4.5172\n",
      "step 6000: train loss 4.3195, val loss 4.5085\n",
      "step 6100: train loss 4.3072, val loss 4.4681\n",
      "step 6200: train loss 4.3055, val loss 4.5007\n",
      "step 6300: train loss 4.2897, val loss 4.4581\n",
      "step 6400: train loss 4.2891, val loss 4.4734\n",
      "step 6500: train loss 4.2778, val loss 4.4656\n",
      "step 6600: train loss 4.2675, val loss 4.4687\n",
      "step 6700: train loss 4.2737, val loss 4.4823\n",
      "step 6800: train loss 4.2730, val loss 4.4589\n",
      "step 6900: train loss 4.2641, val loss 4.4575\n",
      "step 7000: train loss 4.2596, val loss 4.4351\n",
      "step 7100: train loss 4.2581, val loss 4.4795\n",
      "step 7200: train loss 4.2497, val loss 4.4296\n",
      "step 7300: train loss 4.2536, val loss 4.4540\n",
      "step 7400: train loss 4.2381, val loss 4.4832\n",
      "step 7500: train loss 4.2277, val loss 4.4538\n",
      "step 7600: train loss 4.2447, val loss 4.4211\n",
      "step 7700: train loss 4.2400, val loss 4.4708\n",
      "step 7800: train loss 4.2358, val loss 4.5062\n",
      "step 7900: train loss 4.2091, val loss 4.4110\n",
      "step 8000: train loss 4.2107, val loss 4.5004\n",
      "step 8100: train loss 4.2182, val loss 4.3721\n",
      "step 8200: train loss 4.2104, val loss 4.4371\n",
      "step 8300: train loss 4.2315, val loss 4.3809\n",
      "step 8400: train loss 4.1880, val loss 4.4468\n",
      "step 8500: train loss 4.1954, val loss 4.4512\n",
      "step 8600: train loss 4.1989, val loss 4.4567\n",
      "step 8700: train loss 4.1753, val loss 4.4517\n",
      "step 8800: train loss 4.1815, val loss 4.4189\n",
      "step 8900: train loss 4.1796, val loss 4.4020\n",
      "step 9000: train loss 4.1921, val loss 4.4753\n",
      "step 9100: train loss 4.1692, val loss 4.4449\n",
      "step 9200: train loss 4.1602, val loss 4.3811\n",
      "step 9300: train loss 4.1561, val loss 4.4475\n",
      "step 9400: train loss 4.1631, val loss 4.5106\n",
      "step 9500: train loss 4.1673, val loss 4.3500\n",
      "step 9600: train loss 4.1539, val loss 4.4066\n",
      "step 9700: train loss 4.1441, val loss 4.4040\n",
      "step 9800: train loss 4.1477, val loss 4.4515\n",
      "step 9900: train loss 4.1395, val loss 4.3704\n",
      "step 9999: train loss 4.0912, val loss 4.3917\n"
     ]
    }
   ],
   "source": [
    "train_loss = 0\n",
    "val_loss = 0\n",
    "for n in range(num_iters):\n",
    "    x, y = get_batch('train')\n",
    "    with autocast(device_type=\"cuda\"):\n",
    "        logits = model(x)\n",
    "        B, T, C = logits.shape\n",
    "        loss = F.cross_entropy(logits.view(B*T, C), y.view(B*T)) #/ accumulation_steps\n",
    "    scaler.scale(loss).backward()\n",
    "    if (n + 1) % accumulation_steps == 0:\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "    with torch.no_grad():\n",
    "        train_loss += loss #* accumulation_steps\n",
    "        if (n % print_interval == 0 or n == num_iters - 1):\n",
    "            model.eval()\n",
    "            for _ in range(val_iters):\n",
    "                x, y = get_batch('val')\n",
    "                logits = model(x)\n",
    "                B, T, C = logits.shape\n",
    "                val_loss += F.cross_entropy(logits.view(B*T, C), y.view(B*T))\n",
    "            if n==0:\n",
    "                print(f\"step {n}: train loss {train_loss:.4f}, val loss {val_loss/val_iters:.4f}\")\n",
    "            else:\n",
    "                print(f\"step {n}: train loss {train_loss/print_interval:.4f}, val loss {val_loss/val_iters:.4f}\")\n",
    "            train_loss = 0\n",
    "            val_loss = 0\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29b11f3d-744b-4bf5-b7bf-f05bf1e1a59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state\": model.state_dict(),\n",
    "    \"optimizer_state\": optimizer.state_dict(),\n",
    "}, \"imdb_wiki103_checkpoint_10k.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ebde878-c88c-41ee-aa19-c57f9e904878",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "! Larry Silent OK, however, given is full shots of magic, most decor. Especially through the whole movie, despite one scene like a slasher films; one has constant squers falsehoods(under discomfort below.) In Swiss Borepa cooking buffs illustrates this glorious 1970's acted and native whashes of bearded, images. (Romails, violence, intellectual appeal, whatever time he flopging its characters were every by setting's home in the world) when my teenage wife, the timid Races of her parents grow murderous their family \"heart of Mississippi settlers.\" What George was the case of 'Fanny' is a big station and by closing his eyes of a shifty knife. A ravishing father and neurotic and prayed on ideas should have guessed it...<br /><br />The characters are all cute and funny at times very dangerous. There is also little of each other, naked.... that's it was boring, if this strolling off thirties and used each of which a mean I know all the segments would say to the one where Gina walks around the pair a back dance and in the hospital.<br /><br />I think I am surprised to see \"You need the people!! in comparison goes down by.<br /><br />Mr. Andrea Connors, while you know, gaze in the place of escaping through a pub during the results situations appear next night in the jungle, drinks in the garbage. Thompson specpersonal, and decides to play that he needs to take hard drink or waste money! Oh, and hate him, because the leg is I'm not afraid to be confused.<br /><br />For example, One of the most trony of Takeshots from some hill in the impeccable nasty games, but Brian Zombie 'Mler' who doesn't bind it throughout. expect in this story - mostly perhaps this film is cool!<br /><br />I'll hand it right on this is still a very wee bit teen that makes it better always in five years after 'Oh, I guess,etc. if you were at least 30 years ago - saturation. And a bit of bewildering that maybe the children will miss if it is simply action out. There is no good movie, good director I've made a good print of it didn't even enjoy it, but is really bad. I actually accepted rather originality at all. All the story started open with obviously everything else would happen sending people into when\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(tokenizer.decode(model.generate(context, max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c2f28d-d65d-4cad-906e-00fbdf6a2f19",
   "metadata": {},
   "source": [
    "## Finetuning on Supervised IMDB sentiment (Using fc layer on final token for binary classification) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3140ab2f-ba54-458a-96ac-ddceccd4759d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2TokenizerFast\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95e79b93-229a-45ff-a3c4-ac17f08324c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train'].shuffle()\n",
    "test_data = dataset['test'].shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73d01e14-14d6-4415-ae15-7dd99cffac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.eos_token = tokenizer.decode(50256)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc38d216-b5e7-464a-acae-bfa27bce23ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else test_data\n",
    "    ix = torch.randint(len(data)//batch_size, (1,)).item()\n",
    "    x = tokenizer(data[ix*batch_size:(ix+1)*batch_size]['text'], padding='max_length', truncation=True, max_length=block_size, return_tensors=\"pt\")[\"input_ids\"]\n",
    "    y = torch.tensor(data[ix*batch_size:(ix+1)*batch_size]['label'], dtype=torch.float)\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ace2796-14c4-47ea-b855-608351643c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "accumulation_steps = 8\n",
    "block_size = 512\n",
    "num_iters = 500\n",
    "print_interval = 100\n",
    "val_iters = 8\n",
    "lr = 5e-4\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "d_model = 256\n",
    "nhead = 8\n",
    "num_layers = 8\n",
    "dropout = 0.01\n",
    "dim_feedforward = 2048\n",
    "mask = torch.tril(torch.ones(block_size,block_size)).to(device=device)\n",
    "vocab_size = tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e96cf807-1036-48bf-8ed7-24421215df78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 8241,  5690,   287,  ..., 50256, 50256, 50256],\n",
       "         [ 1212,   318,   257,  ..., 50256, 50256, 50256],\n",
       "         [ 1890,   257,  1877,  ..., 50256, 50256, 50256],\n",
       "         ...,\n",
       "         [ 1212,   318,   281,  ..., 50256, 50256, 50256],\n",
       "         [ 2514,   502,   428,  ..., 50256, 50256, 50256],\n",
       "         [ 2025,  4044,    11,  ..., 50256, 50256, 50256]], device='cuda:0'),\n",
       " tensor([1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6872d0f-cc4b-4911-a035-1a6a1d776d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModelSentiment(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = nn.Embedding(vocab_size, d_model)\n",
    "        self.position_embedding = nn.Embedding(block_size, d_model)\n",
    "        self.transformer = Transformer(num_layers, d_model, nhead, dim_feedforward, dropout=dropout)\n",
    "        self.final1 = nn.Linear(d_model, 1)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=(2/d_model)**0.5)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=(2/vocab_size)**0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T = x.shape\n",
    "        tok_emb = self.embedding_layer(x) # (B,T,C)\n",
    "        pos_emb = self.position_embedding(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.transformer(x, mask=mask) # (B,T,C)\n",
    "        logits = self.final1(x[:,-1,:]) # Using last token (B,1) \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad86b2eb-ab37-4342-93cd-ddeeeae8527d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.512065 M parameters\n"
     ]
    }
   ],
   "source": [
    "model = LanguageModelSentiment()\n",
    "checkpoint = torch.load(\"imdb_wiki103_checkpoint_10k.pth\")\n",
    "model.load_state_dict(checkpoint[\"model_state\"], strict=False)\n",
    "model = model.to(device)\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "94c5a861-512c-45ee-9b27-a5fd47bd5a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.512065 M parameters\n"
     ]
    }
   ],
   "source": [
    "model = LanguageModelSentiment()\n",
    "checkpoint = torch.load(\"imdb_wiki103_checkpoint_10k.pth\")\n",
    "model.load_state_dict(checkpoint[\"model_state\"], strict=False)\n",
    "model = model.to(device)\n",
    "print(sum(p.numel() for p in model.parameters())/1e6, 'M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cdc4f81d-d91d-4248-bdb7-388dc53a2e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # Freeze all layers\n",
    "\n",
    "for param in model.transformer.parameters():\n",
    "    param.requires_grad = True  # Unfreeze transformer layer\n",
    "\n",
    "for param in model.final1.parameters():\n",
    "    param.requires_grad = True  # Unfreeze final fc layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3ee3116-9b26-468c-9baf-740eb2d8829c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding_layer.weight: Frozen\n",
      "position_embedding.weight: Frozen\n",
      "transformer.layers.0.self_attn.w_q.weight: Trainable\n",
      "transformer.layers.0.self_attn.w_k.weight: Trainable\n",
      "transformer.layers.0.self_attn.w_v.weight: Trainable\n",
      "transformer.layers.0.self_attn.fc_out.weight: Trainable\n",
      "transformer.layers.0.self_attn.fc_out.bias: Trainable\n",
      "transformer.layers.0.ffn.0.weight: Trainable\n",
      "transformer.layers.0.ffn.0.bias: Trainable\n",
      "transformer.layers.0.ffn.2.weight: Trainable\n",
      "transformer.layers.0.ffn.2.bias: Trainable\n",
      "transformer.layers.0.norm1.weight: Trainable\n",
      "transformer.layers.0.norm1.bias: Trainable\n",
      "transformer.layers.0.norm2.weight: Trainable\n",
      "transformer.layers.0.norm2.bias: Trainable\n",
      "transformer.layers.1.self_attn.w_q.weight: Trainable\n",
      "transformer.layers.1.self_attn.w_k.weight: Trainable\n",
      "transformer.layers.1.self_attn.w_v.weight: Trainable\n",
      "transformer.layers.1.self_attn.fc_out.weight: Trainable\n",
      "transformer.layers.1.self_attn.fc_out.bias: Trainable\n",
      "transformer.layers.1.ffn.0.weight: Trainable\n",
      "transformer.layers.1.ffn.0.bias: Trainable\n",
      "transformer.layers.1.ffn.2.weight: Trainable\n",
      "transformer.layers.1.ffn.2.bias: Trainable\n",
      "transformer.layers.1.norm1.weight: Trainable\n",
      "transformer.layers.1.norm1.bias: Trainable\n",
      "transformer.layers.1.norm2.weight: Trainable\n",
      "transformer.layers.1.norm2.bias: Trainable\n",
      "transformer.layers.2.self_attn.w_q.weight: Trainable\n",
      "transformer.layers.2.self_attn.w_k.weight: Trainable\n",
      "transformer.layers.2.self_attn.w_v.weight: Trainable\n",
      "transformer.layers.2.self_attn.fc_out.weight: Trainable\n",
      "transformer.layers.2.self_attn.fc_out.bias: Trainable\n",
      "transformer.layers.2.ffn.0.weight: Trainable\n",
      "transformer.layers.2.ffn.0.bias: Trainable\n",
      "transformer.layers.2.ffn.2.weight: Trainable\n",
      "transformer.layers.2.ffn.2.bias: Trainable\n",
      "transformer.layers.2.norm1.weight: Trainable\n",
      "transformer.layers.2.norm1.bias: Trainable\n",
      "transformer.layers.2.norm2.weight: Trainable\n",
      "transformer.layers.2.norm2.bias: Trainable\n",
      "transformer.layers.3.self_attn.w_q.weight: Trainable\n",
      "transformer.layers.3.self_attn.w_k.weight: Trainable\n",
      "transformer.layers.3.self_attn.w_v.weight: Trainable\n",
      "transformer.layers.3.self_attn.fc_out.weight: Trainable\n",
      "transformer.layers.3.self_attn.fc_out.bias: Trainable\n",
      "transformer.layers.3.ffn.0.weight: Trainable\n",
      "transformer.layers.3.ffn.0.bias: Trainable\n",
      "transformer.layers.3.ffn.2.weight: Trainable\n",
      "transformer.layers.3.ffn.2.bias: Trainable\n",
      "transformer.layers.3.norm1.weight: Trainable\n",
      "transformer.layers.3.norm1.bias: Trainable\n",
      "transformer.layers.3.norm2.weight: Trainable\n",
      "transformer.layers.3.norm2.bias: Trainable\n",
      "transformer.layers.4.self_attn.w_q.weight: Trainable\n",
      "transformer.layers.4.self_attn.w_k.weight: Trainable\n",
      "transformer.layers.4.self_attn.w_v.weight: Trainable\n",
      "transformer.layers.4.self_attn.fc_out.weight: Trainable\n",
      "transformer.layers.4.self_attn.fc_out.bias: Trainable\n",
      "transformer.layers.4.ffn.0.weight: Trainable\n",
      "transformer.layers.4.ffn.0.bias: Trainable\n",
      "transformer.layers.4.ffn.2.weight: Trainable\n",
      "transformer.layers.4.ffn.2.bias: Trainable\n",
      "transformer.layers.4.norm1.weight: Trainable\n",
      "transformer.layers.4.norm1.bias: Trainable\n",
      "transformer.layers.4.norm2.weight: Trainable\n",
      "transformer.layers.4.norm2.bias: Trainable\n",
      "transformer.layers.5.self_attn.w_q.weight: Trainable\n",
      "transformer.layers.5.self_attn.w_k.weight: Trainable\n",
      "transformer.layers.5.self_attn.w_v.weight: Trainable\n",
      "transformer.layers.5.self_attn.fc_out.weight: Trainable\n",
      "transformer.layers.5.self_attn.fc_out.bias: Trainable\n",
      "transformer.layers.5.ffn.0.weight: Trainable\n",
      "transformer.layers.5.ffn.0.bias: Trainable\n",
      "transformer.layers.5.ffn.2.weight: Trainable\n",
      "transformer.layers.5.ffn.2.bias: Trainable\n",
      "transformer.layers.5.norm1.weight: Trainable\n",
      "transformer.layers.5.norm1.bias: Trainable\n",
      "transformer.layers.5.norm2.weight: Trainable\n",
      "transformer.layers.5.norm2.bias: Trainable\n",
      "transformer.layers.6.self_attn.w_q.weight: Trainable\n",
      "transformer.layers.6.self_attn.w_k.weight: Trainable\n",
      "transformer.layers.6.self_attn.w_v.weight: Trainable\n",
      "transformer.layers.6.self_attn.fc_out.weight: Trainable\n",
      "transformer.layers.6.self_attn.fc_out.bias: Trainable\n",
      "transformer.layers.6.ffn.0.weight: Trainable\n",
      "transformer.layers.6.ffn.0.bias: Trainable\n",
      "transformer.layers.6.ffn.2.weight: Trainable\n",
      "transformer.layers.6.ffn.2.bias: Trainable\n",
      "transformer.layers.6.norm1.weight: Trainable\n",
      "transformer.layers.6.norm1.bias: Trainable\n",
      "transformer.layers.6.norm2.weight: Trainable\n",
      "transformer.layers.6.norm2.bias: Trainable\n",
      "transformer.layers.7.self_attn.w_q.weight: Trainable\n",
      "transformer.layers.7.self_attn.w_k.weight: Trainable\n",
      "transformer.layers.7.self_attn.w_v.weight: Trainable\n",
      "transformer.layers.7.self_attn.fc_out.weight: Trainable\n",
      "transformer.layers.7.self_attn.fc_out.bias: Trainable\n",
      "transformer.layers.7.ffn.0.weight: Trainable\n",
      "transformer.layers.7.ffn.0.bias: Trainable\n",
      "transformer.layers.7.ffn.2.weight: Trainable\n",
      "transformer.layers.7.ffn.2.bias: Trainable\n",
      "transformer.layers.7.norm1.weight: Trainable\n",
      "transformer.layers.7.norm1.bias: Trainable\n",
      "transformer.layers.7.norm2.weight: Trainable\n",
      "transformer.layers.7.norm2.bias: Trainable\n",
      "transformer.norm.weight: Trainable\n",
      "transformer.norm.bias: Trainable\n",
      "final1.weight: Trainable\n",
      "final1.bias: Trainable\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {'Trainable' if param.requires_grad else 'Frozen'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b2119a6-f31c-4998-893c-9f294692509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "print_interval = 500\n",
    "val_iters = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d3a46cf4-52f6-49be-8f59-e5fb336f56d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c620384e-5a9d-4e3c-9bf9-25f539d472c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iters = 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "59be2f06-43c5-45b7-b6b1-0639658d681f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 1.4332, val loss 0.8732, val accuracy 0.5115\n",
      "step 500: train loss 0.7387, val loss 0.6446, val accuracy 0.6819\n",
      "step 1000: train loss 0.4313, val loss 0.3091, val accuracy 0.8711\n",
      "step 1500: train loss 0.2916, val loss 0.3271, val accuracy 0.8599\n",
      "step 2000: train loss 0.2600, val loss 0.3087, val accuracy 0.8688\n",
      "step 2500: train loss 0.2447, val loss 0.2749, val accuracy 0.8865\n",
      "step 3000: train loss 0.2229, val loss 0.2878, val accuracy 0.8821\n",
      "step 3500: train loss 0.2204, val loss 0.2892, val accuracy 0.8821\n",
      "step 4000: train loss 0.1897, val loss 0.2681, val accuracy 0.8940\n",
      "step 4500: train loss 0.1725, val loss 0.2817, val accuracy 0.8891\n",
      "step 5000: train loss 0.1429, val loss 0.2957, val accuracy 0.8886\n",
      "step 5500: train loss 0.1495, val loss 0.2724, val accuracy 0.8973\n",
      "step 5999: train loss 0.1432, val loss 0.2952, val accuracy 0.8916\n"
     ]
    }
   ],
   "source": [
    "train_loss = 0\n",
    "val_loss = 0\n",
    "accuracy = 0\n",
    "for n in range(num_iters):\n",
    "    x, y = get_batch('train')\n",
    "    with autocast(device_type=\"cuda\"):\n",
    "        logits = model(x)\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, y.to(dtype=torch.float).unsqueeze(-1))\n",
    "    scaler.scale(loss).backward()\n",
    "    if (n + 1) % accumulation_steps == 0:\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "    with torch.no_grad():\n",
    "        train_loss += loss #* accumulation_steps\n",
    "        if (n % print_interval == 0 or n == num_iters - 1):\n",
    "            for _ in range(val_iters):\n",
    "                x, y = get_batch('val')\n",
    "                logits = model(x)\n",
    "                val_loss += F.binary_cross_entropy_with_logits(logits, y.to(dtype=torch.float).unsqueeze(-1))\n",
    "                logits = logits.squeeze(-1)\n",
    "                accuracy += torch.isclose(torch.sigmoid(logits).round(), y).to(dtype=torch.float).mean()\n",
    "            if n==0:\n",
    "                print(f\"step {n}: train loss {train_loss:.4f}, val loss {val_loss/val_iters:.4f}, val accuracy {accuracy/val_iters:.4f}\")\n",
    "            else:\n",
    "                print(f\"step {n}: train loss {train_loss/print_interval:.4f}, val loss {val_loss/val_iters:.4f}, val accuracy {accuracy/val_iters:.4f}\")\n",
    "            train_loss = 0\n",
    "            val_loss = 0\n",
    "            accuracy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "85f5858f-2f13-4b7f-9bf1-18cd2d96dbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state\": model.state_dict(),\n",
    "    \"optimizer_state\": optimizer.state_dict(),\n",
    "}, \"sentiment_imdb_wiki103_checkpoint.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a1e7f3-2b3c-4bf8-b7b9-61cbecb59b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
